{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapeando letras de tango"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto constituye el primer intento para generar un scrapper que pueda bajar todas las letras de tango de [todotango](http://www.todotango.com/). Para eso vamos a usar la librería `BeatifulSoup` que sirve para hacer webscraping.\n",
    "\n",
    "**Nota:** Se agradece la colaboración de E. Piccolli en este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from numpy import random\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import json, codecs\n",
    "#%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = urllib2.urlopen('http://www.todotango.com/musica/obras/all/-/0/0/').read()\n",
    "index_soup = soup(index,\"html.parser\")\n",
    "\n",
    "index_link = []\n",
    "for link in index_soup.find_all('a'):\n",
    "    index_link.append(link.get('href'))\n",
    "\n",
    "index_link = index_link[72:(len(index_link)-15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_tango(lista, save_file):\n",
    "    canciones = []\n",
    "    count = 0\n",
    "    data = pd.DataFrame()\n",
    "    for i in lista:\n",
    "        # Open site and parse it\n",
    "\n",
    "        r = urllib2.urlopen(i).read()\n",
    "        page_soup = soup(r,\"html.parser\") \n",
    "\n",
    "        # get text from interesting sections            \n",
    "        titulo = [span.string for span in page_soup.find_all('span', attrs={'id':'main_Tema1_lbl_Titulo'}) ]\n",
    "        ritmo =  [span.string for  span in page_soup.find_all('span', attrs={'id':'main_Tema1_lbl_Ritmo'})]\n",
    "        ano = [span.string for span in page_soup.find_all('span', attrs={'id':'main_Tema1_lbl_Ano'})]\n",
    "        musica = [link.string  for link in page_soup.find_all('a', attrs={'id':'main_Tema1_Tema_Autores1_RP_TemasCreadores_AutoresMusica_hl_Creador_0'})]\n",
    "        compositor = [link.string for link in page_soup.find_all('a', attrs={'id':'main_Tema1_Tema_Autores1_RP_TemasCreadores_AutoresLetra_hl_Creador_0'})]\n",
    "        letra = [span.get_text(' | ')  for span in page_soup.find_all('span', attrs={'id':'main_Tema1_lbl_Letra'})]\n",
    "        \n",
    "        # append the existing dataframe with latest information\n",
    "        # in order to make arrays of the same length to concatenate dataframe need to add \"vacio\" for empty strings\n",
    "        if len(titulo) != 0:\n",
    "            data.set_value(i, 'titulo', titulo)\n",
    "        else:\n",
    "            data.set_value(i, 'titulo', 'vacio')\n",
    "        \n",
    "        if len(ritmo) != 0:\n",
    "            data.set_value(i, 'ritmo', ritmo)\n",
    "        else:\n",
    "            data.set_value(i, 'ritmo', 'vacio')\n",
    "\n",
    "        if len(ano) != 0:\n",
    "            data.set_value(i, 'ano', ano)\n",
    "        else:\n",
    "            data.set_value(i, 'ano', 'vacio')\n",
    "        \n",
    "        if len(musica) != 0:\n",
    "            data.set_value(i, 'musica', musica)\n",
    "        else:\n",
    "            data.set_value(i, 'musica', 'vacio')\n",
    "            \n",
    "        if len(compositor) != 0:\n",
    "            data.set_value(i, 'compositor', compositor)\n",
    "        else:\n",
    "            data.set_value(i, 'compositor', 'vacio')       \n",
    "            \n",
    "        if len(letra) != 0:\n",
    "            data.set_value(i, 'letra', letra)\n",
    "        else:\n",
    "            data.set_value(i, 'letra', 'vacio')\n",
    "        \n",
    "        data.to_csv(save_file, encoding='utf-8')\n",
    "        count += 1\n",
    "        print count,\n",
    "        \n",
    "    return data\n",
    "        \n",
    "        #with open(save_file, 'wb') as f:\n",
    "        #    json.dump(canciones, codecs.getwriter('utf-8')(f), ensure_ascii=False)\n",
    "    #return canciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrap_tango(index_link[0:1000],'tango01.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('tango01.txt') as data_file:\n",
    "    t1 = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tangos_final = []\n",
    "for t in [t1, t2, t3, t4, t5, t6, t7 ,t8, t9, t10]:\n",
    "    for i in t:\n",
    "        tangos_final.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tango_final.txt', 'wb') as f:\n",
    "            json.dump(tangos_final, codecs.getwriter('utf-8')(f), ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
